name: nm build-test
on:
  # makes workflow reusable
  workflow_call:
    inputs:
      wf_category:
        description: "categories: REMOTE, NIGHTLY, WEEKLY, RELEASE"
        type: string
        default: "REMOTE"
      python:
        description: "python version, e.g. 3.10.12"
        type: string
        required: true
      # build related parameters
      build_label:
        description: "requested runner label (specifies instance)"
        type: string
        default: gcp-k8s-build
      build_timeout:
        description: "time limit for build in minutes "
        type: string
        default: "120"
      Gi_per_thread:
        description: 'requested GiB to reserve per thread'
        type: string
        default: "1"
      nvcc_threads:
        description: "number of threads nvcc build threads"
        type: string
        default: "8"
      # test related parameters
      test_label_solo:
        description: "requested runner label (specifies instance)"
        type: string
        required: true
      test_label_multi:
        description: "requested runner label (specifies instance)"
        type: string
        required: true
      test_timeout:
        description: "time limit for test run in minutes "
        type: string
        required: true
      gitref:
        description: "git commit hash or branch name"
        type: string
        required: true
      test_skip_env_vars:
        description: 'file with list of env vars controlling which tests to run'
        type: string
        required: true
      # benchmark related parameters
      benchmark_label:
        description: "requested benchmark label (specifies instance)"
        type: string
        default: ""
      benchmark_config_list_file:
        description: "benchmark configs file, e.g. 'nm_benchmark_nightly_configs_list.txt'"
        type: string
        required: true
      benchmark_timeout:
        description: "time limit for benchmarking"
        type: string
        default: "720"
      push_benchmark_results_to_gh_pages:
        description: "When set to true, the workflow pushes all benchmarking results to gh-pages UI"
        type: string
        default: "false"
      # lm-eval related parameters
      lm_eval_label:
        description: "requested runner label (specifies instance)"
        type: string
        default: ""
      lm_eval_timeout:
        description: "time limit for lm_eval in minutes"
        type: string
        default: "60"
      lm_eval_configuration:
        description: "configuration for lm-eval test (see neuralmagic/lm-eval)"
        type: string
        default: "" 

jobs:

    BUILD:
        uses: ./.github/workflows/nm-build.yml
        with:
            wf_category: ${{ inputs.wf_category }}
            build_label: ${{ inputs.build_label }}
            timeout: ${{ inputs.build_timeout }}
            gitref: ${{ github.ref }}
            Gi_per_thread: ${{ inputs.Gi_per_thread }}
            nvcc_threads: ${{ inputs.nvcc_threads }}
            python: ${{ inputs.python }}
        secrets: inherit

    LM_EVAL:
        needs: [BUILD]
        uses: ./.github/workflows/nm-lm-eval.yml
        with:
          label: ${{ inputs.test_label_solo }}
          timeout: ${{ inputs.test_timeout }}
          gitref: ${{ inputs.gitref }}
          python: ${{ inputs.python }}
          whl: ${{ needs.BUILD.outputs.whl }}
          lm_eval_configuration: ${{ inputs.lm_eval_configuration }}
        secrets: inherit

    ASYNC_ENGINE:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: async_engine
        secrets: inherit
    
    BASIC_CORRECTNESS:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: basic_correctness
        secrets: inherit
    
    CORE:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: core
        secrets: inherit

    DISTRIBUTED:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_multi }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: distributed
        secrets: inherit
    
    ENGINE:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: engine
        secrets: inherit

    ENTRYPOINTS:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: entrypoints
        secrets: inherit
  
    KERNELS:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: kernels
        secrets: inherit
    
    LORA:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: lora
        secrets: inherit
    
    METRICS:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: metrics
        secrets: inherit    

    MODEL_EXECUTOR:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: model_executor
        secrets: inherit
     
    MODELS:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: models
        secrets: inherit 

    MODELS_CORE:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: models_core
        secrets: inherit

    MULTIMODAL:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: multimodal
        secrets: inherit

    PREFIX_CACHING:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: prefix_caching
        secrets: inherit
    
    QUANTIZATION:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: quantization
        secrets: inherit
  
    SAMPLERS:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: samplers
        secrets: inherit
    
    SPEC_DECODE:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: spec_decode
        secrets: inherit

    TENSORIZER:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: tensorizer_loader
        secrets: inherit

    TOKENIZATION:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: tokenization
        secrets: inherit
    
    WORKER:
        needs: [BUILD]
        if: success()
        uses: ./.github/workflows/nm-test.yml
        with:
            test_label: ${{ inputs.test_label_solo }}
            timeout: ${{ inputs.test_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
            whl: ${{ needs.BUILD.outputs.whl }}
            test_skip_env_vars: ${{ inputs.test_skip_env_vars }}
            test_directory: worker
        secrets: inherit

    UPLOAD:
        needs: [LM_EVAL, ASYNC_ENGINE, BASIC_CORRECTNESS, CORE, DISTRIBUTED, ENGINE, ENTRYPOINTS, KERNELS, LORA, METRICS, MODEL_EXECUTOR, MODELS, MODELS_CORE, MULTIMODAL, PREFIX_CACHING, QUANTIZATION, SAMPLERS, SPEC_DECODE, TENSORIZER, TOKENIZATION, WORKER]
        if: contains(fromJSON('["NIGHTLY", "WEEKLY", "RELEASE"]'), inputs.wf_category)
        uses: ./.github/workflows/nm-upload-assets-to-gcp.yml
        with:
            label: ${{ inputs.build_label }}
            timeout: ${{ inputs.build_timeout }}
            gitref: ${{ github.ref }}
            python: ${{ inputs.python }}
        secrets: inherit

    # BENCHMARK:
    #     needs: [BUILD]
    #     if: success()
    #     uses: ./.github/workflows/nm-benchmark.yml
    #     with:
    #         label: ${{ inputs.benchmark_label }}
    #         benchmark_config_list_file: ${{ inputs.benchmark_config_list_file }}
    #         timeout: ${{ inputs.benchmark_timeout }}
    #         gitref: ${{ github.ref }}
    #         python: ${{ inputs.python }}
    #         whl: ${{ needs.BUILD.outputs.whl }}
    #         # Always push if it is a scheduled job
    #         push_benchmark_results_to_gh_pages: "${{ github.event_name == 'schedule' || inputs.push_benchmark_results_to_gh_pages }}"
    #     secrets: inherit
